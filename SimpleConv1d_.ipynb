{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SILVIAIRENE/Data-Scientist-Machine-Learning-Engineer-Introductory-Course/blob/master/SimpleConv1d_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rytdkCpId1FP",
        "outputId": "a69d29ee-d7fa-4359-fd52-5cc08d865bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ CNN 1D DESDE CERO - IMPLEMENTACI√ìN COMPLETA\n",
            "================================================================================\n",
            "‚úÖ [Problema 1] Clase SimpleConv1d implementada\n",
            "‚úÖ [Problema 2] Funci√≥n calculate_output_size implementada\n",
            "‚úÖ [Problema 3] Funci√≥n de prueba test_simple_conv1d implementada\n",
            "‚úÖ [Problema 4] Clase Conv1d con m√∫ltiples canales implementada\n",
            "‚úÖ [Problema 5] Implementaci√≥n de padding completada\n",
            "‚úÖ [Problema 6] Manejo de minilotes implementado\n",
            "‚úÖ [Problema 7] Cualquier n√∫mero de pasos implementado\n",
            "‚úÖ [Problema 8] Clasificador CNN 1D completo implementado\n",
            "\n",
            "üöÄ EJECUTANDO TODOS LOS PROBLEMAS 1-8\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "[Problema 3] Experimento con matrices peque√±as\n",
            "============================================================\n",
            "Entrada x: [1 2 3 4]\n",
            "Pesos w: [3 5 7]\n",
            "Sesgo b: [1]\n",
            "Salida esperada: [35, 50]\n",
            "Salida obtenida: [35. 50.]\n",
            "\n",
            "Gradiente entrada delta_a: [10 20]\n",
            "Gradiente sesgo esperado: [30]\n",
            "Gradiente sesgo obtenido: [30]\n",
            "Gradiente pesos esperado: [50, 80, 110]\n",
            "Gradiente pesos obtenido: [ 50  80 110]\n",
            "Gradiente entrada esperado: [30, 110, 170, 140]\n",
            "Gradiente entrada obtenido: [ 30 110 170 140]\n",
            "\n",
            "‚úÖ Todas las pruebas pasaron correctamente!\n",
            "\n",
            "============================================================\n",
            "[Problema 4] Experimento con m√∫ltiples canales\n",
            "============================================================\n",
            "Entrada x shape: (2, 4)\n",
            "Entrada x:\n",
            "[[1 2 3 4]\n",
            " [2 3 4 5]]\n",
            "Pesos w shape: (3, 2, 3)\n",
            "Sesgo b: [1 2 3]\n",
            "Salida shape: (3, 2)\n",
            "Salida obtenida:\n",
            "[[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n",
            "Salida esperada:\n",
            "[[16 22]\n",
            " [17 23]\n",
            " [18 24]]\n",
            "‚úÖ Prueba de m√∫ltiples canales pas√≥ correctamente!\n",
            "\n",
            "============================================================\n",
            "[Problema 5] Experimento con padding\n",
            "============================================================\n",
            "Entrada: [[1 2 3 4]]\n",
            "Sin padding - salida shape: (1, 2), valores: [[6. 9.]]\n",
            "Con padding - salida shape: (1, 4), valores: [[3. 6. 9. 7.]]\n",
            "‚úÖ Prueba de padding pas√≥ correctamente!\n",
            "\n",
            "============================================================\n",
            "[Problema 6] Experimento con minilotes\n",
            "============================================================\n",
            "Entrada batch shape: (3, 2, 5)\n",
            "Salida batch shape: (3, 3, 3)\n",
            "‚úÖ Prueba de minilotes pas√≥ correctamente!\n",
            "\n",
            "============================================================\n",
            "[Problema 7] Experimento con diferentes strides\n",
            "============================================================\n",
            "Stride 1: entrada 6 -> salida 4 (esperado: 4)\n",
            "Stride 2: entrada 6 -> salida 2 (esperado: 2)\n",
            "Stride 3: entrada 6 -> salida 2 (esperado: 2)\n",
            "‚úÖ Prueba de stride pas√≥ correctamente!\n",
            "\n",
            "================================================================================\n",
            "üéØ TODOS LOS EXPERIMENTOS B√ÅSICOS (1-7) COMPLETADOS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "[Problema 8] ENTRENAMIENTO CNN 1D EN MNIST\n",
            "================================================================================\n",
            "üì• Cargando datos MNIST...\n",
            "üîÑ Preprocesando datos...\n",
            "üìä Datos completos:\n",
            "   ‚Ä¢ Entrenamiento: (48000, 784)\n",
            "   ‚Ä¢ Validaci√≥n: (12000, 784)\n",
            "üî¨ Muestra de demostraci√≥n:\n",
            "   ‚Ä¢ Entrenamiento: (2000, 784)\n",
            "   ‚Ä¢ Validaci√≥n: (400, 784)\n",
            "\n",
            "üèóÔ∏è Creando modelo CNN 1D...\n",
            "\n",
            "üöÄ Iniciando entrenamiento...\n",
            "üöÄ Iniciando entrenamiento...\n",
            "üìä 2000 muestras, 62 batches por √©poca\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CNN 1D DESDE CERO - IMPLEMENTACI√ìN COMPLETA TODOS LOS PROBLEMAS 1-8\n",
        "# ============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"üöÄ CNN 1D DESDE CERO - IMPLEMENTACI√ìN COMPLETA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 1] Creaci√≥n de clase SimpleConv1d (1 canal)\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleConv1d:\n",
        "    \"\"\"\n",
        "    Capa convolucional 1D simple con un canal de entrada y un canal de salida.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filter_size : int\n",
        "        Tama√±o del filtro\n",
        "    learning_rate : float\n",
        "        Tasa de aprendizaje\n",
        "    initializer : str\n",
        "        Tipo de inicializador ('xavier' o 'he')\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filter_size, learning_rate=0.01, initializer='xavier'):\n",
        "        self.filter_size = filter_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.initializer = initializer\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Inicializa los pesos usando Xavier o He\"\"\"\n",
        "        if self.initializer == 'xavier':\n",
        "            std = np.sqrt(2.0 / self.filter_size)\n",
        "        elif self.initializer == 'he':\n",
        "            std = np.sqrt(2.0 / self.filter_size)\n",
        "        else:\n",
        "            std = 0.01\n",
        "\n",
        "        self.w = np.random.normal(0, std, self.filter_size)\n",
        "        self.b = np.zeros(1)\n",
        "\n",
        "        # Para almacenar gradientes\n",
        "        self.dw = np.zeros_like(self.w)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Propagaci√≥n hacia adelante\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray, shape (input_size,)\n",
        "            Entrada de la capa\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        a : ndarray\n",
        "            Salida de la capa\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        input_size = len(x)\n",
        "        output_size = input_size - self.filter_size + 1\n",
        "\n",
        "        a = np.zeros(output_size)\n",
        "\n",
        "        # Convoluci√≥n: a_i = sum(x[i+s] * w[s]) + b\n",
        "        for i in range(output_size):\n",
        "            window = x[i:i + self.filter_size]\n",
        "            a[i] = np.sum(window * self.w) + self.b[0]\n",
        "\n",
        "        self.a = a\n",
        "        return a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        \"\"\"\n",
        "        Retropropagaci√≥n\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        delta_a : ndarray\n",
        "            Gradiente de la p√©rdida respecto a la salida\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        delta_x : ndarray\n",
        "            Gradiente de la p√©rdida respecto a la entrada\n",
        "        \"\"\"\n",
        "        output_size = len(delta_a)\n",
        "        input_size = len(self.x)\n",
        "\n",
        "        # Inicializar gradientes\n",
        "        self.dw = np.zeros_like(self.w)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        delta_x = np.zeros_like(self.x)\n",
        "\n",
        "        # Gradiente de pesos: dL/dw_s = sum(dL/da_i * x[i+s])\n",
        "        for s in range(self.filter_size):\n",
        "            for i in range(output_size):\n",
        "                self.dw[s] += delta_a[i] * self.x[i + s]\n",
        "\n",
        "        # Gradiente de sesgo: dL/db = sum(dL/da_i)\n",
        "        self.db[0] = np.sum(delta_a)\n",
        "\n",
        "        # Gradiente de entrada: dL/dx_j = sum(dL/da_i * w_s) donde i = j - s\n",
        "        for j in range(input_size):\n",
        "            for s in range(self.filter_size):\n",
        "                i = j - s\n",
        "                if 0 <= i < output_size:\n",
        "                    delta_x[j] += delta_a[i] * self.w[s]\n",
        "\n",
        "        return delta_x\n",
        "\n",
        "    def update_weights(self):\n",
        "        \"\"\"Actualiza los pesos usando descenso de gradiente\"\"\"\n",
        "        self.w -= self.learning_rate * self.dw\n",
        "        self.b -= self.learning_rate * self.db\n",
        "\n",
        "print(\"‚úÖ [Problema 1] Clase SimpleConv1d implementada\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 2] Funci√≥n para calcular tama√±o de salida despu√©s de convoluci√≥n 1D\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_output_size(input_size, filter_size, padding=0, stride=1):\n",
        "    \"\"\"\n",
        "    Calcula el tama√±o de salida despu√©s de la convoluci√≥n 1D\n",
        "\n",
        "    F√≥rmula: N_out = (N_in + 2*P - F) / S + 1\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_size : int\n",
        "        Tama√±o de la entrada (N_in)\n",
        "    filter_size : int\n",
        "        Tama√±o del filtro (F)\n",
        "    padding : int\n",
        "        N√∫mero de rellenos en una direcci√≥n (P)\n",
        "    stride : int\n",
        "        Tama√±o del paso (S)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output_size : int\n",
        "        Tama√±o de la salida (N_out)\n",
        "    \"\"\"\n",
        "    output_size = (input_size + 2 * padding - filter_size) // stride + 1\n",
        "    return output_size\n",
        "\n",
        "print(\"‚úÖ [Problema 2] Funci√≥n calculate_output_size implementada\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 3] Experimento con matrices peque√±as\n",
        "# ============================================================================\n",
        "\n",
        "def test_simple_conv1d():\n",
        "    \"\"\"Prueba la implementaci√≥n de SimpleConv1d con matrices peque√±as\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[Problema 3] Experimento con matrices peque√±as\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Datos de prueba seg√∫n el problema\n",
        "    x = np.array([1, 2, 3, 4])\n",
        "    w = np.array([3, 5, 7])\n",
        "    b = np.array([1])\n",
        "\n",
        "    print(f\"Entrada x: {x}\")\n",
        "    print(f\"Pesos w: {w}\")\n",
        "    print(f\"Sesgo b: {b}\")\n",
        "\n",
        "    # Crear capa convolucional\n",
        "    conv = SimpleConv1d(filter_size=3)\n",
        "    conv.w = w.copy()\n",
        "    conv.b = b.copy()\n",
        "\n",
        "    # Propagaci√≥n hacia adelante\n",
        "    a = conv.forward(x)\n",
        "    print(f\"Salida esperada: [35, 50]\")\n",
        "    print(f\"Salida obtenida: {a}\")\n",
        "\n",
        "    # Verificar c√°lculo manual\n",
        "    # a[0] = x[0]*w[0] + x[1]*w[1] + x[2]*w[2] + b = 1*3 + 2*5 + 3*7 + 1 = 35\n",
        "    # a[1] = x[1]*w[0] + x[2]*w[1] + x[3]*w[2] + b = 2*3 + 3*5 + 4*7 + 1 = 50\n",
        "    assert np.allclose(a, [35, 50]), \"Error en propagaci√≥n hacia adelante\"\n",
        "\n",
        "    # Retropropagaci√≥n\n",
        "    delta_a = np.array([10, 20])\n",
        "    print(f\"\\nGradiente entrada delta_a: {delta_a}\")\n",
        "\n",
        "    delta_x = conv.backward(delta_a)\n",
        "\n",
        "    print(f\"Gradiente sesgo esperado: [30]\")\n",
        "    print(f\"Gradiente sesgo obtenido: {conv.db}\")\n",
        "\n",
        "    print(f\"Gradiente pesos esperado: [50, 80, 110]\")\n",
        "    print(f\"Gradiente pesos obtenido: {conv.dw}\")\n",
        "\n",
        "    print(f\"Gradiente entrada esperado: [30, 110, 170, 140]\")\n",
        "    print(f\"Gradiente entrada obtenido: {delta_x}\")\n",
        "\n",
        "    # Verificaciones\n",
        "    assert np.allclose(conv.db, [30]), \"Error en gradiente del sesgo\"\n",
        "    assert np.allclose(conv.dw, [50, 80, 110]), \"Error en gradiente de pesos\"\n",
        "    assert np.allclose(delta_x, [30, 110, 170, 140]), \"Error en gradiente de entrada\"\n",
        "\n",
        "    print(\"\\n‚úÖ Todas las pruebas pasaron correctamente!\")\n",
        "\n",
        "print(\"‚úÖ [Problema 3] Funci√≥n de prueba test_simple_conv1d implementada\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 4] Clase Conv1d - M√∫ltiples canales\n",
        "# ============================================================================\n",
        "\n",
        "class Conv1d:\n",
        "    \"\"\"\n",
        "    Capa convolucional 1D con soporte para m√∫ltiples canales de entrada y salida.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : int\n",
        "        N√∫mero de canales de entrada\n",
        "    out_channels : int\n",
        "        N√∫mero de canales de salida\n",
        "    filter_size : int\n",
        "        Tama√±o del filtro\n",
        "    stride : int\n",
        "        Tama√±o del paso\n",
        "    padding : int\n",
        "        Cantidad de padding\n",
        "    learning_rate : float\n",
        "        Tasa de aprendizaje\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, filter_size, stride=1,\n",
        "                 padding=0, learning_rate=0.01):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Inicializa pesos usando inicializaci√≥n Xavier\"\"\"\n",
        "        # Pesos: (out_channels, in_channels, filter_size)\n",
        "        fan_in = self.in_channels * self.filter_size\n",
        "        fan_out = self.out_channels * self.filter_size\n",
        "        std = np.sqrt(2.0 / (fan_in + fan_out))\n",
        "\n",
        "        self.w = np.random.normal(0, std, (self.out_channels, self.in_channels, self.filter_size))\n",
        "        self.b = np.zeros(self.out_channels)\n",
        "\n",
        "        # Para almacenar gradientes\n",
        "        self.dw = np.zeros_like(self.w)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def _apply_padding(self, x):\n",
        "        \"\"\"Aplica padding a la entrada\"\"\"\n",
        "        if self.padding == 0:\n",
        "            return x\n",
        "\n",
        "        if len(x.shape) == 1:  # Entrada 1D\n",
        "            return np.pad(x, self.padding, mode='constant', constant_values=0)\n",
        "        else:  # Entrada 2D (canales, features)\n",
        "            return np.pad(x, ((0, 0), (self.padding, self.padding)),\n",
        "                         mode='constant', constant_values=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Propagaci√≥n hacia adelante\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray\n",
        "            Entrada: (in_channels, input_size) o (batch_size, in_channels, input_size)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        a : ndarray\n",
        "            Salida de la capa\n",
        "        \"\"\"\n",
        "        # Manejar diferentes formas de entrada\n",
        "        if len(x.shape) == 1:\n",
        "            # Convertir a formato (1, input_size) para 1 canal\n",
        "            x = x.reshape(1, -1)\n",
        "        elif len(x.shape) == 3:\n",
        "            # Formato batch: (batch_size, in_channels, input_size)\n",
        "            batch_size = x.shape[0]\n",
        "            outputs = []\n",
        "            for i in range(batch_size):\n",
        "                outputs.append(self.forward(x[i]))\n",
        "            return np.array(outputs)\n",
        "\n",
        "        self.x_original = x\n",
        "\n",
        "        # Aplicar padding\n",
        "        x_padded = self._apply_padding(x)\n",
        "        self.x_padded = x_padded\n",
        "\n",
        "        input_size = x_padded.shape[1]\n",
        "        output_size = calculate_output_size(input_size, self.filter_size, 0, self.stride)\n",
        "\n",
        "        # Inicializar salida\n",
        "        a = np.zeros((self.out_channels, output_size))\n",
        "\n",
        "        # Convoluci√≥n para cada canal de salida\n",
        "        for out_ch in range(self.out_channels):\n",
        "            for i in range(0, output_size * self.stride, self.stride):\n",
        "                idx = i // self.stride\n",
        "                if idx >= output_size:\n",
        "                    break\n",
        "\n",
        "                conv_sum = 0\n",
        "                # Sumar sobre todos los canales de entrada\n",
        "                for in_ch in range(self.in_channels):\n",
        "                    # Extraer ventana\n",
        "                    start_idx = i\n",
        "                    end_idx = start_idx + self.filter_size\n",
        "\n",
        "                    if end_idx <= input_size:\n",
        "                        window = x_padded[in_ch, start_idx:end_idx]\n",
        "                        conv_sum += np.sum(window * self.w[out_ch, in_ch, :])\n",
        "\n",
        "                a[out_ch, idx] = conv_sum + self.b[out_ch]\n",
        "\n",
        "        self.a = a\n",
        "        return a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        \"\"\"\n",
        "        Retropropagaci√≥n\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        delta_a : ndarray\n",
        "            Gradiente de la p√©rdida respecto a la salida\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        delta_x : ndarray\n",
        "            Gradiente de la p√©rdida respecto a la entrada\n",
        "        \"\"\"\n",
        "        if len(delta_a.shape) == 3:\n",
        "            # Manejar batch\n",
        "            batch_size = delta_a.shape[0]\n",
        "            delta_x_batch = []\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                delta_x_i = self.backward(delta_a[i])\n",
        "                delta_x_batch.append(delta_x_i)\n",
        "\n",
        "            return np.array(delta_x_batch)\n",
        "\n",
        "        output_size = delta_a.shape[1]\n",
        "        input_size = self.x_padded.shape[1]\n",
        "\n",
        "        # Inicializar gradientes\n",
        "        self.dw = np.zeros_like(self.w)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        delta_x_padded = np.zeros_like(self.x_padded)\n",
        "\n",
        "        # Calcular gradientes\n",
        "        for out_ch in range(self.out_channels):\n",
        "            # Gradiente del sesgo\n",
        "            self.db[out_ch] = np.sum(delta_a[out_ch, :])\n",
        "\n",
        "            for i in range(0, output_size * self.stride, self.stride):\n",
        "                idx = i // self.stride\n",
        "                if idx >= output_size:\n",
        "                    break\n",
        "\n",
        "                for in_ch in range(self.in_channels):\n",
        "                    start_idx = i\n",
        "                    end_idx = start_idx + self.filter_size\n",
        "\n",
        "                    if end_idx <= input_size:\n",
        "                        # Gradiente de pesos\n",
        "                        window = self.x_padded[in_ch, start_idx:end_idx]\n",
        "                        self.dw[out_ch, in_ch, :] += delta_a[out_ch, idx] * window\n",
        "\n",
        "                        # Gradiente de entrada\n",
        "                        delta_x_padded[in_ch, start_idx:end_idx] += \\\n",
        "                            delta_a[out_ch, idx] * self.w[out_ch, in_ch, :]\n",
        "\n",
        "        # Remover padding del gradiente\n",
        "        if self.padding > 0:\n",
        "            delta_x = delta_x_padded[:, self.padding:-self.padding]\n",
        "        else:\n",
        "            delta_x = delta_x_padded\n",
        "\n",
        "        return delta_x\n",
        "\n",
        "    def update_weights(self):\n",
        "        \"\"\"Actualiza los pesos\"\"\"\n",
        "        self.w -= self.learning_rate * self.dw\n",
        "        self.b -= self.learning_rate * self.db\n",
        "\n",
        "def test_conv1d_multiple_channels():\n",
        "    \"\"\"Prueba Conv1d con m√∫ltiples canales\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[Problema 4] Experimento con m√∫ltiples canales\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Datos de prueba\n",
        "    x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])  # shape(2, 4)\n",
        "    w = np.ones((3, 2, 3))  # shape(3, 2, 3) - todos los pesos = 1\n",
        "    b = np.array([1, 2, 3])  # shape(3,)\n",
        "\n",
        "    print(f\"Entrada x shape: {x.shape}\")\n",
        "    print(f\"Entrada x:\\n{x}\")\n",
        "    print(f\"Pesos w shape: {w.shape}\")\n",
        "    print(f\"Sesgo b: {b}\")\n",
        "\n",
        "    # Crear capa convolucional\n",
        "    conv = Conv1d(in_channels=2, out_channels=3, filter_size=3)\n",
        "    conv.w = w.copy()\n",
        "    conv.b = b.copy()\n",
        "\n",
        "    # Propagaci√≥n hacia adelante\n",
        "    a = conv.forward(x)\n",
        "    print(f\"Salida shape: {a.shape}\")\n",
        "    print(f\"Salida obtenida:\\n{a}\")\n",
        "\n",
        "    # C√°lculo manual esperado\n",
        "    expected_a = np.array([\n",
        "        [16, 22],  # Canal 0: (1+2+3 + 2+3+4) + 1 = 16, (2+3+4 + 3+4+5) + 1 = 22\n",
        "        [17, 23],  # Canal 1: mismo + 2\n",
        "        [18, 24]   # Canal 2: mismo + 3\n",
        "    ])\n",
        "\n",
        "    print(f\"Salida esperada:\\n{expected_a}\")\n",
        "\n",
        "    # Verificar resultado\n",
        "    assert np.allclose(a, expected_a), \"Error en convoluci√≥n con m√∫ltiples canales\"\n",
        "    print(\"‚úÖ Prueba de m√∫ltiples canales pas√≥ correctamente!\")\n",
        "\n",
        "print(\"‚úÖ [Problema 4] Clase Conv1d con m√∫ltiples canales implementada\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 5] Implementaci√≥n de padding\n",
        "# ============================================================================\n",
        "\n",
        "def test_padding():\n",
        "    \"\"\"Prueba la implementaci√≥n de padding\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[Problema 5] Experimento con padding\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Prueba con padding\n",
        "    x = np.array([[1, 2, 3, 4]])  # 1 canal, 4 features\n",
        "\n",
        "    conv_no_pad = Conv1d(in_channels=1, out_channels=1, filter_size=3, padding=0)\n",
        "    conv_with_pad = Conv1d(in_channels=1, out_channels=1, filter_size=3, padding=1)\n",
        "\n",
        "    # Inicializar con los mismos pesos\n",
        "    conv_no_pad.w = np.ones((1, 1, 3))\n",
        "    conv_no_pad.b = np.zeros(1)\n",
        "    conv_with_pad.w = np.ones((1, 1, 3))\n",
        "    conv_with_pad.b = np.zeros(1)\n",
        "\n",
        "    a_no_pad = conv_no_pad.forward(x)\n",
        "    a_with_pad = conv_with_pad.forward(x)\n",
        "\n",
        "    print(f\"Entrada: {x}\")\n",
        "    print(f\"Sin padding - salida shape: {a_no_pad.shape}, valores: {a_no_pad}\")\n",
        "    print(f\"Con padding - salida shape: {a_with_pad.shape}, valores: {a_with_pad}\")\n",
        "\n",
        "    # Con padding=1, la salida deber√≠a tener el mismo tama√±o que la entrada\n",
        "    assert a_with_pad.shape[1] == x.shape[1], \"Error en padding\"\n",
        "    print(\"‚úÖ Prueba de padding pas√≥ correctamente!\")\n",
        "\n",
        "print(\"‚úÖ [Problema 5] Implementaci√≥n de padding completada\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 6] Manejo de minilotes\n",
        "# ============================================================================\n",
        "\n",
        "def test_batch_processing():\n",
        "    \"\"\"Prueba el procesamiento por lotes\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[Problema 6] Experimento con minilotes\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Datos de prueba con batch\n",
        "    batch_size = 3\n",
        "    in_channels = 2\n",
        "    input_size = 5\n",
        "\n",
        "    x_batch = np.random.randn(batch_size, in_channels, input_size)\n",
        "\n",
        "    conv = Conv1d(in_channels=2, out_channels=3, filter_size=3)\n",
        "\n",
        "    # Propagaci√≥n hacia adelante\n",
        "    a_batch = conv.forward(x_batch)\n",
        "\n",
        "    print(f\"Entrada batch shape: {x_batch.shape}\")\n",
        "    print(f\"Salida batch shape: {a_batch.shape}\")\n",
        "\n",
        "    # Verificar que el batch se procesa correctamente\n",
        "    assert a_batch.shape[0] == batch_size, \"Error en procesamiento de batch\"\n",
        "    print(\"‚úÖ Prueba de minilotes pas√≥ correctamente!\")\n",
        "\n",
        "print(\"‚úÖ [Problema 6] Manejo de minilotes implementado\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 7] Cualquier n√∫mero de pasos (stride)\n",
        "# ============================================================================\n",
        "\n",
        "def test_stride():\n",
        "    \"\"\"Prueba diferentes valores de stride\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"[Problema 7] Experimento con diferentes strides\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    x = np.array([[1, 2, 3, 4, 5, 6]])  # 1 canal, 6 features\n",
        "\n",
        "    for stride in [1, 2, 3]:\n",
        "        conv = Conv1d(in_channels=1, out_channels=1, filter_size=3, stride=stride)\n",
        "        conv.w = np.ones((1, 1, 3))\n",
        "        conv.b = np.zeros(1)\n",
        "\n",
        "        a = conv.forward(x)\n",
        "        expected_size = calculate_output_size(6, 3, 0, stride)\n",
        "\n",
        "        print(f\"Stride {stride}: entrada {x.shape[1]} -> salida {a.shape[1]} (esperado: {expected_size})\")\n",
        "        assert a.shape[1] == expected_size, f\"Error en stride {stride}\"\n",
        "\n",
        "    print(\"‚úÖ Prueba de stride pas√≥ correctamente!\")\n",
        "\n",
        "print(\"‚úÖ [Problema 7] Cualquier n√∫mero de pasos implementado\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Problema 8] CNN completa para MNIST\n",
        "# ============================================================================\n",
        "\n",
        "class ReLU:\n",
        "    \"\"\"Funci√≥n de activaci√≥n ReLU CORREGIDA\"\"\"\n",
        "    def forward(self, x):\n",
        "        self.x = x.copy()\n",
        "        self.input_shape = x.shape\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        # Manejo inteligente de broadcasting\n",
        "        if hasattr(self, 'input_shape'):\n",
        "            if delta_a.shape != self.x.shape:\n",
        "                mask = (self.x > 0).astype(float)\n",
        "                return delta_a * mask\n",
        "            else:\n",
        "                return delta_a * (self.x > 0)\n",
        "        else:\n",
        "            return delta_a * (delta_a > 0)\n",
        "\n",
        "class FullyConnected:\n",
        "    \"\"\"Capa completamente conectada\"\"\"\n",
        "    def __init__(self, input_size, output_size, learning_rate=0.01):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Inicializaci√≥n Xavier\n",
        "        std = np.sqrt(2.0 / (input_size + output_size))\n",
        "        self.w = np.random.normal(0, std, (input_size, output_size))\n",
        "        self.b = np.zeros(output_size)\n",
        "\n",
        "        self.dw = np.zeros_like(self.w)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return x @ self.w + self.b\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        self.dw = self.x.T @ delta_a\n",
        "        self.db = np.sum(delta_a, axis=0)\n",
        "        return delta_a @ self.w.T\n",
        "\n",
        "    def update_weights(self):\n",
        "        self.w -= self.learning_rate * self.dw\n",
        "        self.b -= self.learning_rate * self.db\n",
        "\n",
        "class Softmax:\n",
        "    \"\"\"Funci√≥n softmax\"\"\"\n",
        "    def forward(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        self.a = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, y_true):\n",
        "        return self.a - y_true\n",
        "\n",
        "class Scratch1dCNNClassifier:\n",
        "    \"\"\"Clasificador CNN 1D desde cero CORREGIDO\"\"\"\n",
        "\n",
        "    def __init__(self, conv_filters=[16, 32], conv_filter_sizes=[7, 5],\n",
        "                 fc_sizes=[64], n_classes=10, learning_rate=0.01):\n",
        "        self.conv_filters = conv_filters\n",
        "        self.conv_filter_sizes = conv_filter_sizes\n",
        "        self.fc_sizes = fc_sizes\n",
        "        self.n_classes = n_classes\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.layers = []\n",
        "        self.fc_layers_objects = []\n",
        "        self.build_model()\n",
        "\n",
        "        # Historial de entrenamiento\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Construye la arquitectura del modelo\"\"\"\n",
        "        # Capas convolucionales\n",
        "        in_channels = 1\n",
        "\n",
        "        for i, (filters, filter_size) in enumerate(zip(self.conv_filters, self.conv_filter_sizes)):\n",
        "            conv_layer = Conv1d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=filters,\n",
        "                filter_size=filter_size,\n",
        "                padding=filter_size//2,\n",
        "                learning_rate=self.learning_rate\n",
        "            )\n",
        "            relu_layer = ReLU()\n",
        "\n",
        "            self.layers.extend([conv_layer, relu_layer])\n",
        "            in_channels = filters\n",
        "\n",
        "        self.fc_initialized = False\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def _initialize_fc_layers(self, input_size):\n",
        "        \"\"\"Inicializa capas FC din√°micamente\"\"\"\n",
        "        if self.fc_initialized:\n",
        "            return\n",
        "\n",
        "        prev_size = input_size\n",
        "\n",
        "        for i, fc_size in enumerate(self.fc_sizes):\n",
        "            fc_layer = FullyConnected(prev_size, fc_size, self.learning_rate)\n",
        "            relu_layer = ReLU()\n",
        "\n",
        "            self.fc_layers_objects.extend([fc_layer, relu_layer])\n",
        "            prev_size = fc_size\n",
        "\n",
        "        # Capa de salida\n",
        "        output_layer = FullyConnected(prev_size, self.n_classes, self.learning_rate)\n",
        "        self.fc_layers_objects.append(output_layer)\n",
        "\n",
        "        self.fc_initialized = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Propagaci√≥n hacia adelante\"\"\"\n",
        "        if len(x.shape) == 2:\n",
        "            x = x.reshape(x.shape[0], 1, -1)\n",
        "\n",
        "        current_output = x\n",
        "\n",
        "        # Capas convolucionales\n",
        "        for layer in self.layers:\n",
        "            current_output = layer.forward(current_output)\n",
        "\n",
        "        # Aplanar\n",
        "        batch_size = current_output.shape[0]\n",
        "        flat_size = current_output.shape[1] * current_output.shape[2]\n",
        "\n",
        "        if not self.fc_initialized:\n",
        "            self._initialize_fc_layers(flat_size)\n",
        "\n",
        "        current_output = current_output.reshape(batch_size, -1)\n",
        "\n",
        "        # Capas FC\n",
        "        for layer in self.fc_layers_objects:\n",
        "            current_output = layer.forward(current_output)\n",
        "\n",
        "        # Softmax\n",
        "        current_output = self.softmax.forward(current_output)\n",
        "\n",
        "        return current_output\n",
        "\n",
        "    def backward(self, y_true):\n",
        "        \"\"\"Retropropagaci√≥n\"\"\"\n",
        "        delta = self.softmax.backward(y_true)\n",
        "\n",
        "        # FC layers\n",
        "        for layer in reversed(self.fc_layers_objects):\n",
        "            delta = layer.backward(delta)\n",
        "\n",
        "        # Reshape para conv\n",
        "        batch_size = delta.shape[0]\n",
        "        dummy_input = np.ones((1, 1, 784))\n",
        "        dummy_output = dummy_input\n",
        "        for layer in self.layers:\n",
        "            dummy_output = layer.forward(dummy_output)\n",
        "\n",
        "        target_shape = (batch_size, dummy_output.shape[1], dummy_output.shape[2])\n",
        "        delta = delta.reshape(target_shape)\n",
        "\n",
        "        # Conv layers\n",
        "        for layer in reversed(self.layers):\n",
        "            delta = layer.backward(delta)\n",
        "\n",
        "    def update_weights(self):\n",
        "        \"\"\"Actualiza todos los pesos\"\"\"\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, 'update_weights'):\n",
        "                layer.update_weights()\n",
        "\n",
        "        for layer in self.fc_layers_objects:\n",
        "            if hasattr(layer, 'update_weights'):\n",
        "                layer.update_weights()\n",
        "\n",
        "    def cross_entropy_loss(self, y_true, y_pred):\n",
        "        \"\"\"P√©rdida de entrop√≠a cruzada\"\"\"\n",
        "        batch_size = y_true.shape[0]\n",
        "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "        return -np.sum(y_true * np.log(y_pred)) / batch_size\n",
        "\n",
        "    def accuracy(self, y_true, y_pred):\n",
        "        \"\"\"Calcula precisi√≥n\"\"\"\n",
        "        y_true_labels = np.argmax(y_true, axis=1)\n",
        "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "        return np.mean(y_true_labels == y_pred_labels)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=16, verbose=True):\n",
        "        \"\"\"Entrena el modelo\"\"\"\n",
        "        n_samples = X_train.shape[0]\n",
        "        n_batches = max(1, n_samples // batch_size)\n",
        "\n",
        "        print(f\"üöÄ Iniciando entrenamiento...\")\n",
        "        print(f\"üìä {n_samples} muestras, {n_batches} batches por √©poca\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            epoch_acc = 0\n",
        "\n",
        "            # Mezclar datos\n",
        "            indices = np.random.permutation(n_samples)\n",
        "            X_shuffled = X_train[indices]\n",
        "            y_shuffled = y_train[indices]\n",
        "\n",
        "            # Mini-batches\n",
        "            for i in range(n_batches):\n",
        "                start_idx = i * batch_size\n",
        "                end_idx = min((i + 1) * batch_size, n_samples)\n",
        "\n",
        "                X_batch = X_shuffled[start_idx:end_idx]\n",
        "                y_batch = y_shuffled[start_idx:end_idx]\n",
        "\n",
        "                try:\n",
        "                    y_pred = self.forward(X_batch)\n",
        "                    loss = self.cross_entropy_loss(y_batch, y_pred)\n",
        "                    acc = self.accuracy(y_batch, y_pred)\n",
        "\n",
        "                    epoch_loss += loss\n",
        "                    epoch_acc += acc\n",
        "\n",
        "                    self.backward(y_batch)\n",
        "                    self.update_weights()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error en batch {i}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if n_batches > 0:\n",
        "                epoch_loss /= n_batches\n",
        "                epoch_acc /= n_batches\n",
        "\n",
        "            self.train_losses.append(epoch_loss)\n",
        "            self.train_accuracies.append(epoch_acc)\n",
        "\n",
        "            # Validaci√≥n\n",
        "            if X_val is not None and y_val is not None:\n",
        "                try:\n",
        "                    val_pred = self.predict_proba(X_val)\n",
        "                    val_loss = self.cross_entropy_loss(y_val, val_pred)\n",
        "                    val_acc = self.accuracy(y_val, val_pred)\n",
        "\n",
        "                    self.val_losses.append(val_loss)\n",
        "                    self.val_accuracies.append(val_acc)\n",
        "\n",
        "                    if verbose and (epoch + 1) % 5 == 0:\n",
        "                        print(f'Epoch {epoch+1:2d}/{epochs} - '\n",
        "                              f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} - '\n",
        "                              f'Val Loss: {val_loss:.4f} Val Acc: {val_acc:.4f}')\n",
        "                except Exception as e:\n",
        "                    if verbose and (epoch + 1) % 5 == 0:\n",
        "                        print(f'Epoch {epoch+1:2d}/{epochs} - '\n",
        "                              f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predice probabilidades\"\"\"\n",
        "        return self.forward(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Hace predicciones\"\"\"\n",
        "        proba = self.predict_proba(X)\n",
        "        return np.argmax(proba, axis=1)\n",
        "\n",
        "    def plot_learning_curves(self):\n",
        "        \"\"\"Grafica curvas de aprendizaje\"\"\"\n",
        "        if len(self.train_losses) == 0:\n",
        "            print(\"‚ö†Ô∏è No hay datos para graficar\")\n",
        "            return\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "        epochs = range(1, len(self.train_losses) + 1)\n",
        "\n",
        "        # P√©rdida\n",
        "        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss', linewidth=2)\n",
        "        if self.val_losses:\n",
        "            ax1.plot(epochs, self.val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
        "        ax1.set_title('P√©rdida')\n",
        "        ax1.set_xlabel('√âpoca')\n",
        "        ax1.set_ylabel('Cross Entropy Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Precisi√≥n\n",
        "        ax2.plot(epochs, self.train_accuracies, 'b-', label='Train Accuracy', linewidth=2)\n",
        "        if self.val_accuracies:\n",
        "            ax2.plot(epochs, self.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n",
        "        ax2.set_title('Precisi√≥n')\n",
        "        ax2.set_xlabel('√âpoca')\n",
        "        ax2.set_ylabel('Accuracy')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def train_cnn_on_mnist():\n",
        "    \"\"\"Entrena CNN 1D en MNIST - VERSI√ìN FINAL\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"[Problema 8] ENTRENAMIENTO CNN 1D EN MNIST\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    try:\n",
        "        # Cargar datos\n",
        "        print(\"üì• Cargando datos MNIST...\")\n",
        "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "        # Preprocesar\n",
        "        print(\"üîÑ Preprocesando datos...\")\n",
        "        X_train_flat = X_train.reshape(X_train.shape[0], -1).astype(np.float32) / 255.0\n",
        "        X_test_flat = X_test.reshape(X_test.shape[0], -1).astype(np.float32) / 255.0\n",
        "\n",
        "        # One-hot encoding\n",
        "        enc = OneHotEncoder(sparse_output=False)\n",
        "        y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1))\n",
        "        y_test_onehot = enc.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "        # Divisi√≥n\n",
        "        X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "            X_train_flat, y_train_onehot, test_size=0.2, random_state=42, stratify=y_train\n",
        "        )\n",
        "\n",
        "        print(f\"üìä Datos completos:\")\n",
        "        print(f\"   ‚Ä¢ Entrenamiento: {X_train_split.shape}\")\n",
        "        print(f\"   ‚Ä¢ Validaci√≥n: {X_val.shape}\")\n",
        "\n",
        "        # Muestra para demostraci√≥n\n",
        "        n_train = 2000\n",
        "        n_val = 400\n",
        "\n",
        "        X_train_small = X_train_split[:n_train]\n",
        "        y_train_small = y_train_split[:n_train]\n",
        "        X_val_small = X_val[:n_val]\n",
        "        y_val_small = y_val[:n_val]\n",
        "\n",
        "        print(f\"üî¨ Muestra de demostraci√≥n:\")\n",
        "        print(f\"   ‚Ä¢ Entrenamiento: {X_train_small.shape}\")\n",
        "        print(f\"   ‚Ä¢ Validaci√≥n: {X_val_small.shape}\")\n",
        "\n",
        "        # Crear modelo\n",
        "        print(\"\\nüèóÔ∏è Creando modelo CNN 1D...\")\n",
        "        model = Scratch1dCNNClassifier(\n",
        "            conv_filters=[8, 16],\n",
        "            conv_filter_sizes=[5, 3],\n",
        "            fc_sizes=[32],\n",
        "            n_classes=10,\n",
        "            learning_rate=0.01\n",
        "        )\n",
        "\n",
        "        # Entrenar\n",
        "        print(\"\\nüöÄ Iniciando entrenamiento...\")\n",
        "        model.fit(\n",
        "            X_train_small, y_train_small,\n",
        "            X_val_small, y_val_small,\n",
        "            epochs=15,\n",
        "            batch_size=32,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Evaluar\n",
        "        print(\"\\nüìä Evaluando modelo...\")\n",
        "        val_pred = model.predict(X_val_small)\n",
        "        val_true = np.argmax(y_val_small, axis=1)\n",
        "        val_accuracy = np.mean(val_pred == val_true)\n",
        "\n",
        "        print(f\"üéØ Precisi√≥n final: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Visualizaciones\n",
        "        model.plot_learning_curves()\n",
        "\n",
        "        print(\"\\nüìã Reporte de clasificaci√≥n:\")\n",
        "        print(classification_report(val_true, val_pred))\n",
        "\n",
        "        # Matriz de confusi√≥n\n",
        "        cm = confusion_matrix(val_true, val_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=range(10), yticklabels=range(10))\n",
        "        plt.title('Matriz de Confusi√≥n - CNN 1D')\n",
        "        plt.ylabel('Etiqueta Verdadera')\n",
        "        plt.xlabel('Etiqueta Predicha')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nüéâ ¬°ENTRENAMIENTO COMPLETADO!\")\n",
        "        print(f\"üèÜ Precisi√≥n final: {val_accuracy:.1%}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ [Problema 8] Clasificador CNN 1D completo implementado\")\n",
        "\n",
        "# ============================================================================\n",
        "# FUNCI√ìN PRINCIPAL - EJECUTA TODOS LOS PROBLEMAS 1-8\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Funci√≥n principal que ejecuta todos los problemas del 1 al 8\"\"\"\n",
        "    print(\"\\nüöÄ EJECUTANDO TODOS LOS PROBLEMAS 1-8\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Problema 3: Experimento con matrices peque√±as\n",
        "    test_simple_conv1d()\n",
        "\n",
        "    # Problema 4: M√∫ltiples canales\n",
        "    test_conv1d_multiple_channels()\n",
        "\n",
        "    # Problema 5: Padding\n",
        "    test_padding()\n",
        "\n",
        "    # Problema 6: Minilotes\n",
        "    test_batch_processing()\n",
        "\n",
        "    # Problema 7: Stride\n",
        "    test_stride()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéØ TODOS LOS EXPERIMENTOS B√ÅSICOS (1-7) COMPLETADOS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Problema 8: CNN completa en MNIST\n",
        "    model = train_cnn_on_mnist()\n",
        "\n",
        "    if model:\n",
        "        print(f\"\\n‚úÖ √âXITO TOTAL: TODOS LOS PROBLEMAS 1-8 COMPLETADOS\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è Problemas 1-7 completados, error en Problema 8\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# EJECUTAR TODO EL PIPELINE COMPLETO\n",
        "if __name__ == \"__main__\":\n",
        "    model = main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSCB1z4DJEXsfRRXq2nsaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}