{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRv5+vBEDnEGWV2usMcti1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SILVIAIRENE/Data-Scientist-Machine-Learning-Engineer-Introductory-Course/blob/master/ResNet_y_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk-HhEaCstrN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "abdc39b1-4892-42df-eb00-abbc52daada5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after class definition on line 265 (ipython-input-3446721042.py, line 266)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3446721042.py\"\u001b[0;36m, line \u001b[0;32m266\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 265\n"
          ]
        }
      ],
      "source": [
        "# Sprint 20: Mejora de Precisi√≥n de Segmentaci√≥n con Transfer Learning\n",
        "\n",
        "## TGS Salt Identification Challenge - Comparaci√≥n ResNet vs VGG\n",
        "## ‚úÖ VERSI√ìN ACTUALIZADA 2025 - TENSORFLOW 2.x\n",
        "\n",
        "'Este notebook implementa y compara dos arquitecturas de U-Net usando transfer learning:'\n",
        "#- **U-Net con encoder ResNet50**\n",
        "#- **U-Net con encoder VGG16**\n",
        "\n",
        "### Objetivos:\n",
        "#1. **Problema 1**: Revisar el c√≥digo con transfer learning\n",
        "#2. **Problema 2**: Cambiar de ResNet a VGG en el encoder\n",
        "#3. **Problema 3**: Entrenar ambos modelos y comparar resultados\n",
        "\n",
        "### Versiones Actualizadas:\n",
        "#- TensorFlow 2.19+ (con Keras integrado)\n",
        "#- Python 3.12\n",
        "#- Dependencias compatibles con 2025'''\n",
        "print(\"=== SPRINT 20: SEGMENTACI√ìN CON TRANSFER LEARNING ===\")\n",
        "print(\"TGS Salt Identification Challenge\")\n",
        "print(\"Comparaci√≥n ResNet50-UNet vs VGG16-UNet\")\n",
        "print(\"üöÄ VERSI√ìN ACTUALIZADA 2025 - TENSORFLOW 2.x\")\n",
        "\n",
        "# Verificar versiones\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Instalar/actualizar dependencias compatibles\n",
        "!pip install --upgrade tensorflow>=2.19.0\n",
        "!pip install --upgrade scikit-image\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install --upgrade opencv-python\n",
        "!pip install --upgrade seaborn\n",
        "!pip install --upgrade kaggle\n",
        "\n",
        "print(\"‚úÖ Dependencias instaladas correctamente\")\n",
        "# Importar librer√≠as necesarias\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from skimage import exposure\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TensorFlow 2.x con Keras integrado\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate,\n",
        "    BatchNormalization, Activation, Dropout, GlobalAveragePooling2D,\n",
        "    Dense, Lambda, Conv2DTranspose\n",
        ")\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Configurar seeds para reproducibilidad (sintaxis TF 2.x)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.style.use('default')  # Usar estilo por defecto m√°s compatible\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"‚úÖ Todas las importaciones exitosas\")\n",
        "# Configuraci√≥n de memoria GPU para evitar errores de memoria\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"‚úÖ GPU configurada: {len(gpus)} dispositivos encontrados\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No se encontraron GPUs, usando CPU\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  Configuraci√≥n de GPU omitida\")\n",
        "\n",
        "# Verificar dispositivos disponibles\n",
        "print(\"Dispositivos disponibles:\")\n",
        "print(tf.config.list_physical_devices())\n",
        "print(\"=== DESCARGA DE DATOS TGS SALT IDENTIFICATION CHALLENGE ===\")\n",
        "\n",
        "# Configurar Kaggle API\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Verificar si kaggle.json existe\n",
        "kaggle_path = Path.home() / '.kaggle' / 'kaggle.json'\n",
        "if not kaggle_path.exists():\n",
        "    print(\"‚ùå Por favor, sube tu archivo kaggle.json primero\")\n",
        "    print(\"1. Ve a Account > Create New API Token en Kaggle\")\n",
        "    print(\"2. Sube el archivo kaggle.json usando el bot√≥n de archivos de Colab\")\n",
        "    print(\"3. Ejecuta esta celda nuevamente\")\n",
        "else:\n",
        "    print(\"‚úÖ Archivo kaggle.json encontrado\")\n",
        "\n",
        "# Crear directorio y configurar permisos\n",
        "!mkdir -p ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "try:\n",
        "    # Descargar dataset\n",
        "    !kaggle competitions download -c tgs-salt-identification-challenge\n",
        "    !unzip -q tgs-salt-identification-challenge.zip -d ./tgs-data/\n",
        "\n",
        "    # Listar archivos descargados\n",
        "    !ls -la ./tgs-data/\n",
        "    print(\"‚úÖ Dataset descargado exitosamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error descargando dataset: {e}\")\n",
        "    print(\"Verifica que hayas aceptado las reglas de la competencia en Kaggle\")\n",
        "    # Par√°metros del modelo actualizados\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30  # Reducido para pruebas m√°s r√°pidas\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# Rutas de datos actualizadas\n",
        "DATA_PATH = './tgs-data/'\n",
        "TRAIN_PATH = os.path.join(DATA_PATH, 'train/')\n",
        "TEST_PATH = os.path.join(DATA_PATH, 'test/')\n",
        "\n",
        "print(f\"üìã CONFIGURACI√ìN:\")\n",
        "print(f\"- Tama√±o de imagen: {IMG_WIDTH}x{IMG_HEIGHT}x{IMG_CHANNELS}\")\n",
        "print(f\"- Batch size: {BATCH_SIZE}\")\n",
        "print(f\"- √âpocas: {EPOCHS}\")\n",
        "print(f\"- Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"- Ruta de datos: {DATA_PATH}\")\n",
        "\n",
        "# Verificar que los directorios existen\n",
        "if os.path.exists(TRAIN_PATH):\n",
        "    print(\"‚úÖ Directorio de entrenamiento encontrado\")\n",
        "else:\n",
        "    print(\"‚ùå Directorio de entrenamiento no encontrado\")\n",
        "def rle_decode(mask_rle, shape=(101, 101)):\n",
        "    \"\"\"\n",
        "    Decodifica Run Length Encoding a m√°scara binaria\n",
        "    \"\"\"\n",
        "    if pd.isna(mask_rle):\n",
        "        return np.zeros(shape, dtype=np.uint8)\n",
        "\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape)\n",
        "\n",
        "def rle_encode(img):\n",
        "    \"\"\"\n",
        "    Codifica m√°scara binaria a Run Length Encoding\n",
        "    \"\"\"\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"\n",
        "    Carga y preprocesa los datos de entrenamiento\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Cargar metadatos\n",
        "        train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
        "        depths_df = pd.read_csv(os.path.join(DATA_PATH, 'depths.csv'))\n",
        "\n",
        "        # Merge con informaci√≥n de profundidad\n",
        "        train_df = train_df.merge(depths_df, on='id', how='left')\n",
        "\n",
        "        print(f\"üìä ESTAD√çSTICAS DEL DATASET:\")\n",
        "        print(f\"- Total de im√°genes de entrenamiento: {len(train_df)}\")\n",
        "        print(f\"- Im√°genes con m√°scaras: {len(train_df[~train_df.rle_mask.isna()])}\")\n",
        "        print(f\"- Im√°genes sin m√°scaras: {len(train_df[train_df.rle_mask.isna()])}\")\n",
        "\n",
        "        return train_df\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error cargando datos: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_data_generators(train_df, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    Crea generadores de datos para entrenamiento y validaci√≥n\n",
        "    \"\"\"\n",
        "    if train_df is None:\n",
        "        return None, None\n",
        "\n",
        "    # Dividir en entrenamiento y validaci√≥n\n",
        "    train_ids, val_ids = train_test_split(\n",
        "        train_df.id.values,\n",
        "        test_size=validation_split,\n",
        "        stratify=train_df.rle_mask.isna(),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"üìà DIVISI√ìN DE DATOS:\")\n",
        "    print(f\"- Im√°genes de entrenamiento: {len(train_ids)}\")\n",
        "    print(f\"- Im√°genes de validaci√≥n: {len(val_ids)}\")\n",
        "\n",
        "    return train_ids, val_ids\n",
        "\n",
        "def load_image(image_id, is_train=True):\n",
        "    \"\"\"\n",
        "    Carga y preprocesa una imagen individual\n",
        "    \"\"\"\n",
        "    try:\n",
        "        path = TRAIN_PATH if is_train else TEST_PATH\n",
        "\n",
        "        # Cargar imagen\n",
        "        img_path = os.path.join(path, 'images', f'{image_id}.png')\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if img is None:\n",
        "            raise ValueError(f\"No se pudo cargar la imagen: {img_path}\")\n",
        "\n",
        "        # Convertir a RGB duplicando el canal\n",
        "        img = np.stack([img, img, img], axis=-1)\n",
        "\n",
        "        # Redimensionar\n",
        "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), preserve_range=True)\n",
        "\n",
        "        return img.astype(np.float32) / 255.0\n",
        "    except Exception as e:\n",
        "        print(f\"Error cargando imagen {image_id}: {e}\")\n",
        "        return np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "\n",
        "def load_mask(image_id, train_df):\n",
        "    \"\"\"\n",
        "    Carga y preprocesa una m√°scara individual\n",
        "    \"\"\"\n",
        "    try:\n",
        "        rle_mask = train_df[train_df.id == image_id].rle_mask.iloc[0]\n",
        "        mask = rle_decode(rle_mask)\n",
        "        mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), preserve_range=True)\n",
        "        return mask.astype(np.float32)\n",
        "    except Exception as e:\n",
        "        print(f\"Error cargando m√°scara {image_id}: {e}\")\n",
        "        return np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.float32)\n",
        "\n",
        "# Cargar datos\n",
        "print(\"üîÑ Cargando datos...\")\n",
        "train_df = load_and_preprocess_data()\n",
        "\n",
        "if train_df is not None:\n",
        "    train_ids, val_ids = create_data_generators(train_df, VALIDATION_SPLIT)\n",
        "    print(\"‚úÖ Datos cargados exitosamente\")\n",
        "else:\n",
        "    print(\"‚ùå Error en la carga de datos\")\n",
        "    class DataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"\n",
        "    Generador de datos personalizado compatible con TensorFlow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, image_ids, train_df, batch_size=16, shuffle=True):\n",
        "        self.image_ids = image_ids\n",
        "        self.train_df = train_df\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.image_ids) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_ids = [self.image_ids[k] for k in indexes]\n",
        "        X, y = self.__data_generation(batch_ids)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.image_ids))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, batch_ids):\n",
        "        X = np.empty((self.batch_size, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "        y = np.empty((self.batch_size, IMG_HEIGHT, IMG_WIDTH, 1))\n",
        "\n",
        "        for i, image_id in enumerate(batch_ids):\n",
        "            # Cargar imagen\n",
        "            X[i] = load_image(image_id)\n",
        "\n",
        "            # Cargar m√°scara\n",
        "            mask = load_mask(image_id, self.train_df)\n",
        "            y[i] = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "if train_ids is not None and val_ids is not None:\n",
        "    # Crear generadores\n",
        "    train_generator = DataGenerator(train_ids, train_df, BATCH_SIZE, shuffle=True)\n",
        "    val_generator = DataGenerator(val_ids, train_df, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    print(f\"üìä GENERADORES CREADOS:\")\n",
        "    print(f\"- Generador de entrenamiento: {len(train_generator)} batches\")\n",
        "    print(f\"- Generador de validaci√≥n: {len(val_generator)} batches\")\n",
        "    print(\"‚úÖ Generadores listos\")\n",
        "else:\n",
        "    print(\"‚ùå No se pudieron crear los generadores\")\n",
        "    def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Calcula el coeficiente Dice (F1-score para segmentaci√≥n)\n",
        "    Compatible con TensorFlow 2.x\n",
        "    \"\"\"\n",
        "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Funci√≥n de p√©rdida basada en Dice coefficient\n",
        "    \"\"\"\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Combina Binary Cross-Entropy con Dice Loss\n",
        "    \"\"\"\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    return 0.5 * bce + 0.5 * dice\n",
        "\n",
        "def iou_metric(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Calcula Intersection over Union (IoU)\n",
        "    Compatible con TensorFlow 2.x\n",
        "    \"\"\"\n",
        "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "# Funci√≥n de Tversky Loss (adicional para mejor rendimiento)\n",
        "def tversky_loss(y_true, y_pred, alpha=0.3, beta=0.7, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Tversky Loss - √∫til para datos desbalanceados\n",
        "    \"\"\"\n",
        "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
        "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
        "\n",
        "    true_pos = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    false_neg = tf.reduce_sum(y_true_f * (1 - y_pred_f))\n",
        "    false_pos = tf.reduce_sum((1 - y_true_f) * y_pred_f)\n",
        "\n",
        "    tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
        "    return 1 - tversky\n",
        "\n",
        "print(\"‚úÖ M√©tricas definidas: Dice Coefficient, Dice Loss, Combined Loss, IoU, Tversky Loss\")\n",
        "print(\"=\" * 70)\n",
        "print(\"PROBLEMA 1: AN√ÅLISIS DE TRANSFER LEARNING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\"\"\n",
        "üéØ ¬øQU√â ES TRANSFER LEARNING?\n",
        "\n",
        "Transfer Learning es una t√©cnica donde utilizamos un modelo pre-entrenado\n",
        "en un dataset grande (como ImageNet) y adaptamos sus caracter√≠sticas\n",
        "aprendidas para nuestro problema espec√≠fico.\n",
        "\n",
        "üîÑ DIFERENCIAS CON LA IMPLEMENTACI√ìN B√ÅSICA:\n",
        "\n",
        "1. **Encoder Pre-entrenado**: En lugar de entrenar desde cero, utilizamos\n",
        "   pesos de modelos entrenados en ImageNet (millones de im√°genes)\n",
        "\n",
        "2. **Feature Extraction**: Aprovechamos caracter√≠sticas de bajo nivel ya\n",
        "   aprendidas (bordes, texturas, formas, patrones)\n",
        "\n",
        "3. **Convergencia m√°s r√°pida**: El modelo converge m√°s r√°pido al partir\n",
        "   de pesos pre-entrenados\n",
        "\n",
        "4. **Mejor precisi√≥n**: Especialmente √∫til cuando tenemos datasets limitados\n",
        "\n",
        "5. **Menos recursos**: Requiere menos tiempo de entrenamiento\n",
        "\n",
        "‚öôÔ∏è C√ìMO IMPLEMENTAMOS TRANSFER LEARNING:\n",
        "\n",
        "1. **Cargar modelo pre-entrenado**: ResNet50 o VGG16 entrenados en ImageNet\n",
        "2. **Congelar capas iniciales**: Para mantener caracter√≠sticas de bajo nivel\n",
        "3. **Fine-tuning**: Permitir el entrenamiento de capas superiores\n",
        "4. **Adaptaci√≥n de decoder**: Dise√±ar decoder espec√≠fico para segmentaci√≥n\n",
        "5. **Skip connections**: Conectar capas del encoder con el decoder\n",
        "\n",
        "üìä VENTAJAS EN SEGMENTACI√ìN:\n",
        "- Mejor detecci√≥n de bordes y contornos\n",
        "- Reconocimiento de texturas complejas\n",
        "- Adaptaci√≥n r√°pida a dominios espec√≠ficos\n",
        "- Menor sobreajuste con datos limitados\n",
        "\"\"\")\n",
        "def build_resnet_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    \"\"\"\n",
        "    Construye U-Net con encoder ResNet50 pre-entrenado\n",
        "    Compatible con TensorFlow 2.x y Keras integrado\n",
        "    \"\"\"\n",
        "\n",
        "    # =============================================\n",
        "    # ENCODER: ResNet50 Pre-entrenado\n",
        "    # =============================================\n",
        "\n",
        "    # Cargar ResNet50 pre-entrenado (sin clasificador final)\n",
        "    base_model = ResNet50(\n",
        "        weights='imagenet',  # Pesos pre-entrenados en ImageNet\n",
        "        include_top=False,   # Sin clasificador final\n",
        "        input_shape=input_shape,\n",
        "        input_tensor=None\n",
        "    )\n",
        "\n",
        "    print(f\"üî• ResNet50 cargado: {len(base_model.layers)} capas\")\n",
        "\n",
        "    # Obtener capas espec√≠ficas para skip connections\n",
        "    # Estas capas proporcionan caracter√≠sticas a diferentes resoluciones\n",
        "    layer_names = [layer.name for layer in base_model.layers]\n",
        "    print(f\"üìã Capas disponibles: {len(layer_names)} capas\")\n",
        "\n",
        "    # Intentar encontrar las capas apropiadas\n",
        "    skip_layers = []\n",
        "    skip_outputs = []\n",
        "\n",
        "    # Buscar capas por patrones conocidos\n",
        "    input_layer = base_model.input\n",
        "    skip_outputs.append(input_layer)  # Input original (128x128)\n",
        "\n",
        "    # Buscar capas intermedias\n",
        "    for layer in base_model.layers:\n",
        "        if any(pattern in layer.name.lower() for pattern in\n",
        "               ['conv1', 'conv2_block3', 'conv3_block4', 'conv4_block6']):\n",
        "            if hasattr(layer, 'output'):\n",
        "                skip_outputs.append(layer.output)\n",
        "                skip_layers.append(layer.name)\n",
        "\n",
        "    print(f\"üîó Skip connections encontradas: {len(skip_outputs)}\")\n",
        "    for i, name in enumerate(skip_layers):\n",
        "        print(f\"   - Capa {i+1}: {name}\")\n",
        "\n",
        "    # Bottleneck (centro de la U-Net)\n",
        "    bottleneck = base_model.output\n",
        "    print(f\"üèóÔ∏è Bottleneck shape: {bottleneck.shape}\")\n",
        "\n",
        "    # =============================================\n",
        "    # DECODER: Upsampling con Skip Connections\n",
        "    # =============================================\n",
        "\n",
        "    # Decoder Block 1: Upsampling inicial\n",
        "    x = UpSampling2D(size=(2, 2))(bottleneck)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Decoder Block 2\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Skip connection si est√° disponible\n",
        "    if len(skip_outputs) > 4:\n",
        "        try:\n",
        "            x = concatenate([x, skip_outputs[-1]])\n",
        "        except:\n",
        "            pass  # Continuar sin skip connection si hay error\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Decoder Block 3\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Skip connection si est√° disponible\n",
        "    if len(skip_outputs) > 3:\n",
        "        try:\n",
        "            # Ajustar dimensiones si es necesario\n",
        "            skip_tensor = skip_outputs[-2]\n",
        "            if skip_tensor.shape[1:3] == x.shape[1:3]:\n",
        "                x = concatenate([x, skip_tensor])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Decoder Block 4\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Skip connection con input original\n",
        "    if len(skip_outputs) > 0:\n",
        "        try:\n",
        "            if skip_outputs[0].shape[1:3] == x.shape[1:3]:\n",
        "                x = concatenate([x, skip_outputs[0]])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Final upsampling si es necesario\n",
        "    x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # =============================================\n",
        "    # OUTPUT LAYER\n",
        "    # =============================================\n",
        "\n",
        "    # Capa final de segmentaci√≥n\n",
        "    output = Conv2D(1, (1, 1), activation='sigmoid', name='segmentation_output')(x)\n",
        "\n",
        "    # Crear modelo\n",
        "    model = Model(inputs=base_model.input, outputs=output, name='ResNet50_UNet')\n",
        "\n",
        "    # =============================================\n",
        "    # CONFIGURACI√ìN DE TRANSFER LEARNING\n",
        "    # =============================================\n",
        "\n",
        "    # Congelar capas del encoder (transfer learning)\n",
        "    num_layers_to_freeze = len(base_model.layers) - 20  # Congelar todas menos las √∫ltimas 20\n",
        "\n",
        "    for i, layer in enumerate(base_model.layers):\n",
        "        if i < num_layers_to_freeze:\n",
        "            layer.trainable = False\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "\n",
        "    trainable_layers = sum([1 for layer in model.layers if layer.trainable])\n",
        "    frozen_layers = len(model.layers) - trainable_layers\n",
        "\n",
        "    print(f\"üèóÔ∏è MODELO RESNET-UNET CREADO:\")\n",
        "    print(f\"   - Capas totales: {len(model.layers)}\")\n",
        "    print(f\"   - Capas entrenables: {trainable_layers}\")\n",
        "    print(f\"   - Capas congeladas: {frozen_layers}\")\n",
        "    print(f\"   - Par√°metros totales: {model.count_params():,}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear modelo ResNet-UNet\n",
        "print(\"=\" * 70)\n",
        "print(\"üèóÔ∏è CONSTRUYENDO MODELO U-NET CON RESNET50\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    resnet_model = build_resnet_unet()\n",
        "\n",
        "    # Compilar modelo con optimizador moderno\n",
        "    resnet_model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),  # Sintaxis actualizada\n",
        "        loss=combined_loss,\n",
        "        metrics=[dice_coefficient, iou_metric, 'binary_accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ Modelo ResNet-UNet compilado exitosamente\")\n",
        "\n",
        "    # Mostrar resumen del modelo (opcional)\n",
        "    # resnet_model.summary()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creando modelo ResNet: {e}\")\n",
        "    resnet_model = None\n",
        "    print(\"=\" * 70)\n",
        "print(\"PROBLEMA 2: REESCRITURA DE C√ìDIGO - RESNET A VGG\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def build_vgg_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    \"\"\"\n",
        "    Construye U-Net con encoder VGG16 pre-entrenado\n",
        "    Compatible con TensorFlow 2.x\n",
        "\n",
        "    DIFERENCIAS CON RESNET:\n",
        "    1. VGG16 tiene arquitectura m√°s simple (secuencial)\n",
        "    2. No tiene skip connections residuales internas\n",
        "    3. Usa solo convoluciones 3x3 y max pooling\n",
        "    4. Menos par√°metros que ResNet50\n",
        "    5. Arquitectura m√°s interpretable\n",
        "    \"\"\"\n",
        "\n",
        "    # =============================================\n",
        "    # ENCODER: VGG16 Pre-entrenado\n",
        "    # =============================================\n",
        "\n",
        "    # Cargar VGG16 pre-entrenado (sin clasificador final)\n",
        "    base_model = VGG16(\n",
        "        weights='imagenet',  # Pesos pre-entrenados en ImageNet\n",
        "        include_top=False,   # Sin clasificador final\n",
        "        input_shape=input_shape,\n",
        "        input_tensor=None\n",
        "    )\n",
        "\n",
        "    print(f\"üî• VGG16 cargado: {len(base_model.layers)} capas\")\n",
        "\n",
        "    # VGG16 tiene nombres de capas m√°s predecibles\n",
        "    skip_connections = {}\n",
        "\n",
        "    # Buscar capas espec√≠ficas para skip connections\n",
        "    for layer in base_model.layers:\n",
        "        if 'block1_conv2' in layer.name:\n",
        "            skip_connections['block1'] = layer.output\n",
        "        elif 'block2_conv2' in layer.name:\n",
        "            skip_connections['block2'] = layer.output\n",
        "        elif 'block3_conv3' in layer.name:\n",
        "            skip_connections['block3'] = layer.output\n",
        "        elif 'block4_conv3' in layer.name:\n",
        "            skip_connections['block4'] = layer.output\n",
        "\n",
        "    print(f\"üîó Skip connections VGG16: {len(skip_connections)} encontradas\")\n",
        "    for name, tensor in skip_connections.items():\n",
        "        print(f\"   - {name}: {tensor.shape}\")\n",
        "\n",
        "    # Input y Bottleneck\n",
        "    input_tensor = base_model.input\n",
        "    bottleneck = base_model.output  # 4x4x512\n",
        "    print(f\"üèóÔ∏è Bottleneck VGG16 shape: {bottleneck.shape}\")\n",
        "\n",
        "    # =============================================\n",
        "    # DECODER: Upsampling con Skip Connections\n",
        "    # =============================================\n",
        "\n",
        "    # Decoder Block 1: 4x4 -> 8x8\n",
        "    x = UpSampling2D(size=(2, 2))(bottleneck)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "\n",
        "\"...\"\n",
        "\n",
        "\"Let me reevaluate and take a different approach.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "3zHoZeHzaa3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}